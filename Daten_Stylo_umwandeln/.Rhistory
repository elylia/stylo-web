#1 = zufriedenstellende bis sehr gute Gesundheit
df_sub_b$gesundheit_b <- car::recode(df_sub_b$gesundheit, "1=0;2=0; else=1")
df_sub_b$gesundheit <- NULL
#Subdatensatz sichten
summary(df_sub_b)
head(df_sub_b)
###Visualisierungen mit GGplot
df_sub_f <- df_sub
df_sub_f$internet_f <- factor(df_sub_f$internet)
df_sub_f$geschlecht_f <- factor(df_sub_f$geschlecht)
#Nach Geschlecht
labels_1<- c("0" = "männlich", "1" = "weiblich")
ggplot(data=df_sub_f, mapping = aes(x= internet_f, fill = geschlecht_f)) +
geom_bar() +
labs(x = "Internetnutzung") +
ggtitle("Internetnutzung nach Geschlecht") +
theme(plot.title = element_text(hjust = 0.5)) +
facet_wrap(geschlecht_f ~ .,
labeller = labeller(geschlecht_f = labels_1)) +
scale_fill_discrete(name = "Geschlecht", labels = c("männlich", "weiblich"))
#Internetnutzung in Abhängigkeit vom Alter
ggplot(data=df_sub_f, mapping = aes(x=internet_f, y=alter, color=alter)) +
geom_jitter() +
labs(x = "Internetnutzung", y= "Alter") +
ggtitle("Internetnutzung nach Alter") +
theme(plot.title = element_text(hjust = 0.5))
#Internetnutzung in Abhängigkeit vom Nettoeinkommen
ggplot(data=df_sub_f, mapping = aes(x=internet_f, y=einkommen_net, color=einkommen_net)) +
geom_jitter() +
labs(x = "Internetnutzung", y= "Nettoeinkommen") +
ggtitle("Internetnutzung nach Nettoeinkommen") +
theme(plot.title = element_text(hjust = 0.5))
#Internetnutzung und Fernsehnutzung
labels_2<- c("1" = "Ohne Abschluss", "2" = "Volks-/Hauptschule", "3" = "Mittlere Reife", "4" = "Fachabitur", "5" = "Abitur", "6" = "Anderer Abschluss")
ggplot(data=df_sub_f, mapping = aes(x=internet_f, y=tv, color=tv)) +
geom_point() +
labs(x = "Internetnutzung", y= "Fernsehnutzung") +
ggtitle("Internetnutzung und Fernsehnutzung") +
theme(plot.title = element_text(hjust = 0.5)) +
facet_grid(. ~ bildung,
labeller=labeller(bildung = labels_2))
###Subsets aus metrischen Variablen für PCA
#Subset aus Variablen, die den Gesundheitszustand beschreiben
df_sub_pca_gesundheit <- df_sub[,c("ausgeglichen", "energie", "internet_chat", "internet_spiel", "internet_freq", "gesundheit")]
summary(df_sub_pca_gesundheit)
#Subset aus Variablen, die Freizeitaktivitäten beschreiben
df_sub_pca_freizeit <- df_sub[,c("sport", "lesen", "internet_freq", "internet_chat", "internet_spiel", "basteln", "museen", "konzerte_kl", "faulenzen")]
summary(df_sub_pca_freizeit)
###Principal Component Analysis
##PCA: Gesundheit
#Es wird der Datensatz df_sub_pca_gesundheit verwendet
#Skalieren
df_sub.scale_g <- data.frame(scale(df_sub_pca_gesundheit))
summary(df_sub.scale_g)
df_sub.pca_g <- PCA(df_sub.scale_g,
scale.unit = F,
ncp = 5,
graph = F)
print(df_sub.pca_g)
#Eigenwerte ausgeben
df_sub.pca_g$eig
#Scree plot: Welche Dimensionen sind relevant?
#Elbogen Kriterium: Erste drei Dimensionen bilden ca. 70% der Varianz ab
fviz_eig(df_sub.pca_g,
addlabels = TRUE)
###Ergebnisse
var_g <- df_sub.pca_g$var
names(var_g)
#Koordinaten
show(var_g$coord)
#Cos2: Wie gut passt ein Pfeil zu einer Dimension?
head(var_g$cos2)
#Erste und zweite Dimension
fviz_pca_var(df_sub.pca_g,
axes = c(1,2), # which axes to plot
col.var = "cos2", # vars for colours
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),  # color scale [white,blue, red]
repel = TRUE # Avoid text overlapping
)
#Variablen "internet_chat" und "internet_freq" hängen zusammen
#Variablen "ausgeglichen" und "energie" hängen zusammen
#Variablen "internet_chat"/"internet_freq" entgegen der Variablen "ausgeglichen" und "energie"
###Anteil der Variablen an den Dimensionen
#Plotten
corrplot(var_g$cos2, is.corr=FALSE)
#Hoher Anteil an Dimension 1: ausgeglichen, energie, gesundheit
#Mittelhoher Anteil an Dimension 1: internet_chat, internet_freq
#Hoher Anteil an Dimension 2: internet_chat, internet_spiel, internet_freq
#Mittelhoher Anteil an Dimension 2: energie, ausgeglichen
#Hoher Anteil an Dimension 3: internet_spiel
#Plotten des Anteil in Prozent als Bar Plot
#show(var$contrib)
#Dimension 1
fviz_contrib(df_sub.pca_g, choice = "var", axes = 1, top = 10) # pc1
#Nur energie, gesundheit, ausgeglichen liegen über dem Durchschnittswert
#Dimension 2
fviz_contrib(df_sub.pca_g, choice = "var", axes = 2, top = 10) # pc2
#Nur internet_chat, internet_spiel, internet_freq liegen über dem Durchschnittswert
#Dimension 3
fviz_contrib(df_sub.pca_g, choice = "var", axes = 3, top = 10) #pc3
#internet_spiel liegt deutlich über dem Durchschnittswert
# Red line: *expected average contribution*, i.e., $1/length(variables)
##PCA: Freizeitaktivitäten
#Es wird der Datensatz df_sub_pca_freizeit verwendet
#Skalieren
df_sub.scale <- data.frame(scale(df_sub_pca_freizeit))
summary(df_sub.scale)
df_sub.pca <- PCA(df_sub.scale,
scale.unit = F,
ncp = 5,
graph = F)
print(df_sub.pca)
#Eigenwerte ausgeben
df_sub.pca$eig
#Scree plot: Welche Dimensionen sind relevant?
#Elbogen Kriterium: Erste drei Dimensionen bilden ca. 52% der Varianz ab /Erste fünf Dimensionen bilden ca. 72% der Varianz ab
fviz_eig(df_sub.pca,
addlabels = TRUE)
###Ergebnisse
var <- df_sub.pca$var
names(var)
#Koordinaten
show(var$coord)
#Cos2: Wie gut passt ein Pfeil zu einer Dimension?
head(var$cos2)
#Erste und zweite Dimension
fviz_pca_var(df_sub.pca,
axes = c(1,2), # which axes to plot
col.var = "cos2", # vars for colours
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),  # color scale [white,blue, red]
repel = TRUE # Avoid text overlapping
)
#internet_freq entgegen von lesen
#Variablen museen und konzerte_kl korrelieren
#internet_spiel entgegen von museen/konzert_kl und sport
#Erste und dritte Dimension
fviz_pca_var(df_sub.pca,
axes = c(1,3), # which axes to plot
col.var = "cos2", # vars for colours
gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),  # color scale [white,blue, red]
repel = TRUE # Avoid text overlapping
)
#Variablen internet_freq/internet_chat/internet_spiel hängen zusammen und stehen entgegengesetzt zu den Variablen basteln/lesen
###Anteil der Variablen an den Dimensionen
#Plotten
corrplot(var$cos2, is.corr=FALSE)
#Hoher Anteil an Dimension 1: internet_chat, internet_freq
#Mittelhoher Anteil an Dimension 1: lesen, internet_spiel
#Hoher Anteil an Dimension 2: konzerte_kl, museen
#Mittelhoher Anteil an Dimension 2: sport
#Hoher Anteil an Dimension 3: basteln
#Plotten des Anteil in Prozent als Bar Plot
#show(var$contrib)
#Dimension 1
fviz_contrib(df_sub.pca, choice = "var", axes = 1, top = 10) # pc1
#Deutlich über dem Durchschnitswert liegen internet_chat und internet_freq
#Geringfügig über dem Durchschnittswert liegen lesen und internet_spiel
#Dimension 2
fviz_contrib(df_sub.pca, choice = "var", axes = 2, top = 10) # pc2
#Deutlich über dem Durchschnitswert liegen konzerte_kl und museen
#Geringfügig über dem Durchschnittswert liegt sport
#Dimension 3
fviz_contrib(df_sub.pca, choice = "var", axes = 3, top = 10) #pc3
#Deutlich über dem Durchschnitswert liegt basteln
#Geringfügig über dem Durchschnittswert liegt internet_freq
# Red line: *expected average contribution*, i.e., $1/length(variables)
###Unsupervised Learning: Logistische Regression
#Es wird das Subset df_sub_b verwendet
#Internet
#0 = keine private Internetnutzung
#1 = private Internetnutzung
###Model 1: Internetnutzung und politisches Interesse
#Politisches Interesse
#0 = wenig bis gar kein Interesse
#1 = mittel bis starkes Interesse
log.me <- glm(internet ~ polit_int_b,
data = df_sub_b,
family = "binomial")
summary(log.me)
stargazer(log.me, title = "Model 1: Internetnutzung und politisches Interesse", style = "all", type = "html")
odds_1 <- exp(coef(log.me))
odds_1
# Probability: 1 / (1 + exp(coef))
prop_polit_int <- 1 / (1+ exp(1.3828))
prop_polit_int
#Log-Odd: 1.3828 -> positiver Zusammenhang
#Odds-Ratio: 3.986055 -> größer 1: Bei politischem Interesse zunehmende Wahrscheinlichkeit für private Internetnutzung
#Bei politischem Interesse steigt die Wahrscheinlichkeit für private Internetnutzung um ca. 20%
### Model 2: Internetnutzung und Bildung
#Bildung
#0 = sonstige Schulabschlüsse/kein Abschluss
#1 = Fachhochschulreife/Hochschulreife
log.me2 <- glm(internet ~ bildung_b,
data = df_sub_b,
family = "binomial")
summary(log.me2)
stargazer(log.me2, title = "Model 2: Internetnutzung und Bildung", style = "all", type = "html")
odds_2 <- exp(coef(log.me2))
odds_2
# Probability: 1 / (1 + exp(coef))
prop_bildung_b <- 1 / (1+ exp(2.5672))
prop_bildung_b
#Log-Odd: 2.5672 -> positiver Zusammenhang
#Odds-Ratio: 13.02917 -> größer 1: Bei Fachhochschulreife/Hochschulreife zunehmende Wahrscheinlichkeit für private Internetnutzung
#Bei Fachhochschulreife/Hochschulreife steigt die Wahrscheinlichkeit für private Internetnutzung um ca. 7%
### Model 3: Internetnutzung und Geschlecht
#Geschlecht
#0 = männlich
#1 = weiblich
log.me3 <- glm(internet ~ geschlecht,
data = df_sub_b,
family = "binomial")
summary(log.me3)
stargazer(log.me3, title = "Model 3: Internetnutzung und Geschlecht", style = "all", type = "html")
odds_3 <- exp(coef(log.me3))
odds_3
# Probability: 1 / (1 + exp(coef))
prop_geschlecht <- 1 / (1+ exp(-0.1949))
prop_geschlecht
#Effekt nicht signifikant: Kein Zusammenhang zwischen Geschlecht und Internetnutzung
### Model 4: Internetnutzung und Lebenszufriedenheit
#Lebenszufriedenheit
#0 = eher unzufrieden
#1 = eher zufrieden
log.me4 <- glm(internet ~ lebenszufriedenheit_b,
data = df_sub_b,
family = "binomial")
summary(log.me4)
stargazer(log.me4, title = "Model 4: Internetnutzung und Lebenszufriedenheit", style = "all", type = "html")
odds_4 <- exp(coef(log.me4))
odds_4
# Probability: 1 / (1 + exp(coef))
prop_lebenszufriedenheit <- 1 / (1+ exp(0.8718))
prop_lebenszufriedenheit
#Wenig signifikant
#Log-Odd: 0.8718 -> positiver Zusammenhang
#Odds-Ratio: 2.391322 -> größer 1: Bei eher vorhandener Lebenszufriedenheit zunehmende Wahrscheinlichkeit für private Internetnutzung
#Bei eher vorhandener Lebenszufriedenheit steigt die Wahrscheinlichkeit für private Internetnutzung um ca. 29%
###Supervised learning
summary(df_sub_b)
###Split training/test sample
set.seed(404)
#Aufteilung: 70% Trainingsdaten, 30% Testdaten
train.index <- createDataPartition(df_sub_b$internet,
p=0.7,
list=FALSE)
head(train.index)
length(train.index)
0.7 * nrow(df_sub_b)
#Anwenden
training <- df_sub_b[train.index,]
testing<- df_sub_b[-train.index,]
#Oversampling notwendig, da 'imbalanced data': Die Ausprägung "0" (kein Internet) der Variable "internet" ist sehr viel seltener als die Ausprägung "1" (nutzt Internet) vertreten. Im Trainingsdatensatz wird durch Duplikation die kleinere Klasse, "0", der größeren Klasse, "1", quantitativ angeglichen.
table(training$internet)
prop.table(table(training$internet))
training_balanced_over <- ovun.sample(internet ~ ., data = training, method = "over",N = 1926)$data
table(training_balanced_over$internet)
nrow(training_balanced_over); nrow(testing)
###Model trainieren
#Logistische Regression
model.log <- glm(internet ~ .,
family=binomial(link="logit"),
data=training_balanced_over)
summary(model.log)
#Visualisierung
suppressWarnings(odd.ratio <- exp(cbind(OR = coef(model.log), confint(model.log))))
odd.ratio
odd.ratio <- odd.ratio[-1,]
odd.ratio <- as.data.frame(odd.ratio)
odd.ratio$term <- row.names(odd.ratio)
colnames(odd.ratio) <- c("estimate", "conf.low","conf.high", "term")
odd.ratio <- odd.ratio[order(odd.ratio$estimate),]
fitted.log <- predict(model.log,
newdata=testing,
type='response')
fitted.log <- ifelse(fitted.log > 0.5, 1, 0)
mis.classi <- mean(fitted.log != testing$internet)
print(paste('Logistic Regression Accuracy',
(1 - round(mis.classi, 4)) ))
print("Confusion Matrix for Logistic Regression"); table(testing$internet, fitted.log > 0.5)
###Decision tree
sapply(training_balanced_over, FUN = class)
model.tree <- ctree(internet~ alter + bildung_b + polit_int_b + lebenszufriedenheit_b,
data = training_balanced_over)
plot(as.simpleparty(model.tree),
gp = gpar(fontsize = 5),
abbreviate = TRUE,
pval = F,
id = FALSE)
character.var <- sapply(testing, FUN = is.character)
for(i in names(testing)[character.var]){
testing[, i] <- as.factor(testing[, i])
}
fitted.tree <- predict(model.tree, testing)
print("Confusion Matrix for Decision Tree"); table(testing$internet, fitted.tree > 0.5)
tab <- table(Predicted = fitted.tree > 0.5,
Actual = testing$internet)
print(paste('Decision Tree Accuracy bei ausgewählten unabhängigen Variablen (alter + bildung_b + polit_int_b + lebenszufriedenheit_b)',sum(diag(tab))/sum(tab)))
###k-nearest neighbors (KNN)
#Abhängige Variable faktorisieren
#Modell trainieren
model.knn <- train(as.factor(internet) ~ .,
data=training_balanced_over,
method='knn')
model.knn
coefs.knn <- varImp(model.knn)
#Die wichtigsten Variablen
plot(coefs.knn, main="Variable Importance with KNN")
fitted.knn <- predict(model.knn, testing)
head(fitted.knn)
#Confusion Matrix
confusionMatrix(reference = as.factor(testing$internet),
data = fitted.knn)
###Naive Bayes
#Model trainieren
class(training_balanced_over$internet)
suppressWarnings({
model.nb = train(as.factor(internet) ~ .,
data = training_balanced_over,
method = 'nb')
model.nb
coefs.nb <- varImp(model.nb)
plot(coefs.nb, main="Variable Importance")
#Accuracy
model.fit <- predict(model.nb, testing)
head(model.fit)
confusionMatrix(reference = as.factor(testing$internet),
data = model.fit)
})
###Modelle vergleichen
#Wiederholung mit caret: logit und decision tree
model.knn <- train(as.factor(internet) ~ .,
data=training_balanced_over,
method='knn')
model.log <- train(as.factor(internet) ~ .,
data=training_balanced_over,
method='glm')
model.tree <- train(as.factor(internet) ~ .,
data=training_balanced_over,
method='ctree')
suppressWarnings(model.nb <- train(as.factor(internet) ~ .,
data=training_balanced_over,
method='nb'))
model_list2 <- list(glm = model.log, nb = model.nb, knn = model.knn, tree = model.tree)
for(i in model_list2){
fitted.model <- predict(i, testing)
confus <- confusionMatrix(reference = as.factor(testing$internet),
data = fitted.model)
cat('Confusion matrix of ', i$modelInfo$label, '\n') # "\n" = new line
print(confus)
}
###F1 Score
f1score <- function(confus){
# confus == caret::confusionmatrix
fn <- confus$table[2,1]
fp <- confus$table[1,2]
tp <- confus$table[2,2]
prec <- tp / (tp + fp)
rec <- tp / (tp + fn)
f1 <- 2 * (prec * rec) / (prec + rec)
cat('Precision: ', prec, '\n',
'Recall: ', rec, '\n',
'F1: ', f1, '\n')
}
#Logistische Regression
confus.log <- confusionMatrix(model.log)
f1score(confus.log)
#decision tree
confus.tree <- confusionMatrix(model.tree)
f1score(confus.tree)
#knn
confus.knn <- confusionMatrix(model.knn)
f1score(confus.knn)
#naive bayes
confus.nb <- confusionMatrix(model.nb)
f1score(confus.nb)
install.packages("ape")
install.packages("ape")
install.packages("ape")
install.packages("ape")
install.packages("ape")
install.packages("ape")
install.packages("ape")
library(stylo)
stylo()
stylo()
library(stylo)
stylo()
stylo()
library(stylo)
setwd("~/Documents/Master/Masterarbeit/Code_Web_App/Daten_Stylo_umwandeln")
stylo()
stylo()
library("stylo")
library("ape")
library("jsonlite")
library("treeio")
library("TreeTools")
mfw_min = 100
mfw_max = 500
mfw_incr = 100
consensus_strength = 0.5
bootstrap.list = list()
counter = 1
for (i in seq(mfw_min, mfw_max, by=mfw_incr)){
data_bct <- stylo(gui = FALSE, corpus.dir = "corpus", analysis.type = "CA", mwf.min = mfw_min, mfw.max = mfw_min)
mfw_min = mfw_min + mfw_incr
current.bootstrap.result = as.phylo(hclust(as.dist(data_bct$distance.table),
method = "ward.D"))
bootstrap.list[[counter]] = current.bootstrap.result
counter = counter+1
}
consensus.data <- consensus(bootstrap.list, p=consensus_strength)
plot(consensus(bootstrap.list, p=consensus_strength),
type="u",
font=1,
lab4ut="axial")
write.tree(consensus.data, file = "", append = FALSE,digits = 10, tree.names = TRUE)
tree <- as.Newick(consensus.data)
tree <- as.Newick(consensus.data)
write.jtree(consensus.data, file = "", append = FALSE,digits = 10, tree.names = TRUE)
write.jtree(consensus.data, file = "")
library("stylo")
library("ape")
library("jsonlite")
library("treeio")
library("TreeTools")
mfw_min = 100
mfw_max = 500
mfw_incr = 100
consensus_strength = 0.5
bootstrap.list = list()
counter = 1
for (i in seq(mfw_min, mfw_max, by=mfw_incr)){
data_bct <- stylo(gui = FALSE, corpus.dir = "corpus", analysis.type = "CA", mwf.min = mfw_min, mfw.max = mfw_min)
mfw_min = mfw_min + mfw_incr
current.bootstrap.result = as.phylo(hclust(as.dist(data_bct$distance.table),
method = "ward.D"))
bootstrap.list[[counter]] = current.bootstrap.result
counter = counter+1
}
consensus.data <- consensus(bootstrap.list, p=consensus_strength)
plot(consensus(bootstrap.list, p=consensus_strength),
type="u",
font=1,
lab4ut="axial")
write.tree(consensus.data, file = "", append = FALSE,digits = 10, tree.names = TRUE)
write.jtree(consensus.data)
write.tree(consensus.data, file = "", append = FALSE,digits = 10, tree.names = TRUE)
write.tree(consensus.data, file = "", append = FALSE,digits = 10, tree.names = FALSE)
write.tree(consensus.data, file = "", append = TRUE, digits = 10, tree.names = TRUE)
write.tree(consensus.data, file = "", append = FALSE,digits = 10, tree.names = FALSE)
write.tree(consensus.data, file = "", append = FALSE,digits = 10, tree.names = TRUE)
View(consensus.data)
class(consensus.data)
install.packages(tidyverse)
install.packages("tidyverse")
View(consensus.data)
consensus.data %>%
rename(
node.label = branch.length,
)
consensus.data %>%
rename(
node.label = branch.length,
)
library("tidyverse")
consensus.data %>%
rename(
node.label = branch.length,
)
View(data_bct)
View(consensus.data)
consensus.data[["node.label"]]
consensus.data[["edge.length"]] <- consensus.data[["node.label"]]
write.tree(consensus.data, file = "", append = FALSE,digits = 10, tree.names = TRUE)
consensus.data <- consensus(bootstrap.list, p=consensus_strength)
View(data_bct)
View(current.bootstrap.result)
View(consensus.data)
View(current.bootstrap.result)
View(consensus.data)
consensus.data[["node.length"]] <- consensus.data[["node.label"]]
write.tree(consensus.data, file = "", append = FALSE,digits = 10, tree.names = TRUE)
consensus.data <- consensus(bootstrap.list, p=consensus_strength)
library("stylo")
library("ape")
library("treeio")
mfw_min = 100
mfw_max = 500
mfw_incr = 100
consensus_strength = 0.5
bootstrap.list = list()
counter = 1
for (i in seq(mfw_min, mfw_max, by=mfw_incr)){
data_bct <- stylo(gui = FALSE, corpus.dir = "corpus", analysis.type = "CA", mwf.min = mfw_min, mfw.max = mfw_min)
mfw_min = mfw_min + mfw_incr
current.bootstrap.result = as.phylo(hclust(as.dist(data_bct$distance.table),
method = "ward.D"))
bootstrap.list[[counter]] = current.bootstrap.result
counter = counter+1
}
consensus.data <- consensus(bootstrap.list, p=consensus_strength)
plot(consensus(bootstrap.list, p=consensus_strength),
type="u",
font=1,
lab4ut="axial")
write.tree(consensus.data, file = "", append = FALSE,digits = 10, tree.names = TRUE)
write.tree(consensus.data, file = "", append = FALSE,digits = 10, tree.names = FALSE)
write.tree(consensus.data, file = "", append = FALSE,digits = 10, tree.names = TRUE)
write.jtree(consensus.data)
as.Newick(consensus.data)
